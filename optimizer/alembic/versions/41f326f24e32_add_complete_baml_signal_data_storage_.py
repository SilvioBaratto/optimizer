"""Add complete BAML signal data storage to stock_signals

Revision ID: 41f326f24e32
Revises: 02ed4a8dfce3
Create Date: 2025-10-15 17:23:35.010118

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '41f326f24e32'
down_revision: Union[str, Sequence[str], None] = '02ed4a8dfce3'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    # Create the confidence_level_enum type first
    confidence_level_enum = postgresql.ENUM('LOW', 'MEDIUM', 'HIGH', name='confidence_level_enum', create_type=False)
    confidence_level_enum.create(op.get_bind(), checkfirst=True)

    op.add_column('stock_signals', sa.Column('confidence_level', sa.Enum('LOW', 'MEDIUM', 'HIGH', name='confidence_level_enum'), nullable=True, comment='Confidence level in signal: low, medium, high'))
    op.add_column('stock_signals', sa.Column('valuation_score', sa.Float(), nullable=True, comment='Valuation score: -1 (overvalued) to +1 (undervalued)'))
    op.add_column('stock_signals', sa.Column('valuation_summary', sa.Text(), nullable=True, comment='Brief valuation assessment (1-2 sentences)'))
    op.add_column('stock_signals', sa.Column('momentum_score', sa.Float(), nullable=True, comment='Momentum score: -1 (downtrend) to +1 (uptrend)'))
    op.add_column('stock_signals', sa.Column('momentum_summary', sa.Text(), nullable=True, comment='Brief momentum assessment (1-2 sentences)'))
    op.add_column('stock_signals', sa.Column('quality_score', sa.Float(), nullable=True, comment='Quality score: 0 (poor) to 1 (excellent)'))
    op.add_column('stock_signals', sa.Column('quality_summary', sa.Text(), nullable=True, comment='Brief quality assessment (1-2 sentences)'))
    op.add_column('stock_signals', sa.Column('growth_score', sa.Float(), nullable=True, comment='Growth score: -1 (contracting) to +1 (high growth)'))
    op.add_column('stock_signals', sa.Column('growth_summary', sa.Text(), nullable=True, comment='Brief growth assessment (1-2 sentences)'))
    op.add_column('stock_signals', sa.Column('technical_score', sa.Float(), nullable=True, comment='Technical score: -1 (bearish) to +1 (bullish)'))
    op.add_column('stock_signals', sa.Column('technical_summary', sa.Text(), nullable=True, comment='Brief technical assessment (1-2 sentences)'))
    op.add_column('stock_signals', sa.Column('analyst_score', sa.Float(), nullable=True, comment='Analyst sentiment score: -1 (sell) to +1 (buy)'))
    op.add_column('stock_signals', sa.Column('analyst_summary', sa.Text(), nullable=True, comment='Brief analyst sentiment summary (1-2 sentences)'))
    op.add_column('stock_signals', sa.Column('volatility_level', sa.String(length=50), nullable=True, comment='Volatility assessment: Low/Medium/High'))
    op.add_column('stock_signals', sa.Column('beta_risk', sa.Text(), nullable=True, comment='Market sensitivity assessment'))
    op.add_column('stock_signals', sa.Column('debt_risk', sa.Text(), nullable=True, comment='Assessment of debt levels and financial leverage'))
    op.add_column('stock_signals', sa.Column('liquidity_risk', sa.Text(), nullable=True, comment='Assessment of trading liquidity and market depth'))
    op.add_column('stock_signals', sa.Column('data_gaps', postgresql.JSONB(astext_type=sa.Text()), nullable=True, comment='List of missing or unreliable data points (JSON array)'))
    op.add_column('stock_signals', sa.Column('primary_risks', postgresql.JSONB(astext_type=sa.Text()), nullable=True, comment='Top 3-5 key risks to the signal thesis (JSON array)'))
    op.add_column('stock_signals', sa.Column('upside_potential_pct', sa.Float(), nullable=True, comment='Estimated upside % to fair value or target'))
    op.add_column('stock_signals', sa.Column('downside_risk_pct', sa.Float(), nullable=True, comment='Estimated downside % risk to support levels'))
    op.create_index(op.f('ix_stock_signals_confidence_level'), 'stock_signals', ['confidence_level'], unique=False)
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_stock_signals_confidence_level'), table_name='stock_signals')
    op.drop_column('stock_signals', 'downside_risk_pct')
    op.drop_column('stock_signals', 'upside_potential_pct')
    op.drop_column('stock_signals', 'primary_risks')
    op.drop_column('stock_signals', 'data_gaps')
    op.drop_column('stock_signals', 'liquidity_risk')
    op.drop_column('stock_signals', 'debt_risk')
    op.drop_column('stock_signals', 'beta_risk')
    op.drop_column('stock_signals', 'volatility_level')
    op.drop_column('stock_signals', 'analyst_summary')
    op.drop_column('stock_signals', 'analyst_score')
    op.drop_column('stock_signals', 'technical_summary')
    op.drop_column('stock_signals', 'technical_score')
    op.drop_column('stock_signals', 'growth_summary')
    op.drop_column('stock_signals', 'growth_score')
    op.drop_column('stock_signals', 'quality_summary')
    op.drop_column('stock_signals', 'quality_score')
    op.drop_column('stock_signals', 'momentum_summary')
    op.drop_column('stock_signals', 'momentum_score')
    op.drop_column('stock_signals', 'valuation_summary')
    op.drop_column('stock_signals', 'valuation_score')
    op.drop_column('stock_signals', 'confidence_level')

    # Drop the confidence_level_enum type
    confidence_level_enum = postgresql.ENUM('LOW', 'MEDIUM', 'HIGH', name='confidence_level_enum')
    confidence_level_enum.drop(op.get_bind(), checkfirst=True)
    # ### end Alembic commands ###
